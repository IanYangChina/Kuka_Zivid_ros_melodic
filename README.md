### Calibration, Registration-based automatic grasping project

####Robotics and Autonomous Systems Lab, Engineering School, Cardiff University

<img src="/CardiffUnivLogo.jpg" width="80"/>

#### Instruction to use the grasping_demo package

#### 1. Hardware (Network) connection

Before running any scripts of this package, please check the following steps are completed.

1.1 Zivid camera and the Robotiq gripper should connect to the server via USB.

1.2 Power up Kuka Sunrise, camera and gripper.

1.3 Connect the Kuka Sunrise Cabinet with the server via network wire.

1.4 Setup the manual ip address on the Ubuntu GUI as follow:

- IP: 160.69.69.100
- Mask: 255.255.255.0
- Gateway: 160.69.69.0 

1.5 Restart the network connection of the server, you should see a notification saying "network connection established".

1.6 On a new terminal (or your .bashrc file):

- `export ROS_IP=160.69.69.100`
- `export ROS_MASTER_URI=http://$ROS_IP:11311`

1.7 Te test the connection with Sunrise, open a new terminal on Ubuntu and run `roscore`. Then, set the Sunrise Smartpad
to automatic mode and run the `ROSSmartServo` application. You should see the application successfully running.

*1.8 To return to internet, reconnect the previous net wire, set system to automatic ip and restart network.

#### 2. Camera driver, build and source the project

2.1 Following the [Zivid ros driver](https://github.com/zivid/zivid-ros) github to setup your zivid camera SDK and 
ros driver. It is recommended to run a few tutorials in the zivid official repository to test the camera before using
this package.

2.2 Go to the root of this project `.../Zivid_project/`, run `catkin build` and `source devel/setup.bash`. Add `--extend`
to the source command if you need to activate multiple catkin workspaces.

2.3 The project contains the robotiq gripper driver, so you don't need to install it from somewhere else.

#### 3. Run the cmd_prompt script

3.1 On a new terminal, run `rosrun grasping_demo command_prompt.py`

3.2 **Pay attention to the output on the terminal screen**. 

3.3 The script will start a roscore and 3 nodes first:

- A `zivid_camera` node, for capturing point clouds
- A `pcd_processing` node, for registration and compute grasping poses
- A `robotiq_controller` node, for controlling the gripper fingers

3.4 Then you will be prompted to start the `ROSSmartServo` application on the Sunrise Smartpad. Start the application
and input `y` on the terminal, and press `enter`.

3.5 Now the script will start a `kuka_controller node` and initialize the robot and gripper. You should see the
gripper fingers closing and opening, and may see the robot move to a waiting position if it is not already there.

3.6 Then you will be prompted to start a new grasping trial. Following the prompts on the terminal, you can:

- Capture a point cloud and receive a estimated grasping pose. The grasping pose will be visualized for your decision.
The grey object you see in the visualization is the reference object, the blue one is the one you just placed. There
are two frames in the visualization, one is the world frame (robot base), the other is the grasping pose. **Don't** accept 
the pose if the **blue** axis is not properly pointing to the object from above the object near its centre. 
- Accept the pose and see the robot executing it, grasping (and lifting up) the object.
- Discard the pose and rerun the point cloud processing algorithm, or re-capture a point cloud.
- Run as many trials as you want.
- Stop the script when a trial finishes.

#### 4. Extra notes

4.1 The grasping pose is generated by register a new point cloud onto a reference point cloud, which has been labeled
with a ground truth grasping pose.

4.2 The registration algorithm is based on the Open3d (0.9.0) package. It has two steps:
- [Fast global registration using FPFH features](https://github.com/intel-isl/FastGlobalRegistration/blob/master/docs/fast-global-registration.pdf)
- ICP local refinement

4.3 Algorithm parameters have been tuned for the experiment object in our lab. It is recommended to re-tune them for
your own usage (see the python file `src/grasping_demo/src/grasping_demo/pcd_registration.py`).